# ADR-004: Streaming Pipeline for QA Package Execution

## Status
Accepted

## Date
2026-01-30

## Context

QAWave executes QA packages containing multiple test scenarios. Each scenario:
1. Is generated by AI (slow: 2-10 seconds per scenario)
2. Contains multiple test steps
3. Executes HTTP requests against the target API
4. Requires result evaluation

A sequential approach would mean:
```
Generate ALL scenarios → Then execute ALL → Then evaluate ALL
```

This is inefficient because:
- User waits for all AI generation before seeing any results
- AI generation (slow) blocks test execution (fast)
- Resources underutilized during AI wait times

## Decision

We adopted a **Streaming Pipeline** architecture where AI generation and test execution happen in parallel using Kotlin Flow.

### Architecture

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                         STREAMING PIPELINE                                   │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│  Operations ──┬──► [AI Worker 1] ──┬──► [Executor 1] ──┬──► Results         │
│               ├──► [AI Worker 2] ──┼──► [Executor 2] ──┤                    │
│               ├──► [AI Worker 3] ──┼──► [Executor 3] ──┤                    │
│               ├──► [AI Worker 4] ──┼──► [Executor ...] ─┤                    │
│               └──► [AI Worker 5] ──┴──► [Executor 10] ─┴──► Collected       │
│                                                                              │
│  AI Semaphore: 5 permits          Exec Semaphore: 10 permits                │
└─────────────────────────────────────────────────────────────────────────────┘
```

### Flow Implementation

```kotlin
@Service
class QaPackageRunService(
    private val scenarioGenerator: ScenarioGeneratorAgent,
    private val testExecutor: TestExecutor,
    private val eventPublisher: EventPublisher
) {
    private val aiSemaphore = Semaphore(5)  // Limit concurrent AI calls
    private val execSemaphore = Semaphore(10) // Limit concurrent HTTP calls

    suspend fun runPackage(request: RunPackageRequest): QaPackageRun {
        val planId = UUID.randomUUID().toString()

        // Parse OpenAPI operations
        val operations = openApiParser.parse(request.openApiSpec)

        // Create streaming pipeline
        val results = operations.asFlow()
            // Stage 1: Generate scenarios (parallel with limit)
            .map { operation ->
                aiSemaphore.withPermit {
                    val scenario = scenarioGenerator.generateForOperation(operation)
                    eventPublisher.publish(ScenarioCreatedEvent(planId, scenario))
                    scenario
                }
            }
            // Stage 2: Execute scenarios (parallel with limit)
            .flatMapMerge(concurrency = 10) { scenario ->
                flow {
                    execSemaphore.withPermit {
                        val result = testExecutor.execute(scenario, request.baseUrl)
                        eventPublisher.publish(ExecutionCompleteEvent(planId, result))
                        emit(result)
                    }
                }
            }
            // Collect all results
            .toList()

        return buildQaPackageRun(planId, results)
    }
}
```

### State Machine

QA Package runs follow a defined state machine:

```
REQUESTED → SPEC_FETCHED → [SCENARIO_CREATED + EXECUTION_* interleaved...]
                                                          ↓
    ← ← ← ← ← ← ← ← ← ← ← ← ← FAILED ← ← ← ← ← ← ← ← ← ← ↓
    ↓                                                     ↓
    └───────────────────────────────────────────────────► AI_SUCCESS
                                                          ↓
                                                    QA_EVAL_DONE
                                                          ↓
                                                      COMPLETE
```

### Event Types

| Event | Description | When |
|-------|-------------|------|
| `REQUESTED` | QA package run initiated | Start |
| `SPEC_FETCHED` | OpenAPI spec fetched and parsed | After spec fetch |
| `SCENARIO_CREATED` | Individual scenario saved | Per scenario |
| `EXECUTION_SUCCESS` | Scenario passed | Per scenario |
| `EXECUTION_FAILED` | Scenario failed | Per scenario |
| `AI_SUCCESS` | All AI generation completed | All scenarios generated |
| `AI_FAILED` | AI generation failed | On AI error |
| `QA_EVAL_DONE` | QA evaluation completed | After all executions |
| `COMPLETE` | Entire pipeline finished | End |
| `FAILED` | Pipeline failed | On error |

### Concurrency Configuration

```yaml
qawave:
  execution:
    ai-concurrency: 5         # Parallel AI calls
    http-concurrency: 10      # Parallel HTTP calls
    scenario-timeout-ms: 60000
    step-timeout-ms: 30000
```

## Consequences

### Positive
- **Faster overall execution**: Execution starts as soon as first scenario is generated
- **Real-time progress**: Frontend can show incremental results
- **Resource efficiency**: AI and HTTP calls overlap, maximizing throughput
- **Backpressure handling**: Semaphores prevent overwhelming external services

### Negative
- More complex than sequential execution
- Debugging interleaved operations harder
- Event ordering requires careful handling
- Error propagation across parallel streams needs attention

### Trade-offs
- Complexity vs Performance: We accept complexity for 2-3x faster execution
- Events may arrive out of order: Frontend must handle this

## Error Handling

```kotlin
// Per-scenario error handling - failures don't stop the pipeline
.catch { e ->
    logger.error("Scenario generation failed", e)
    eventPublisher.publish(AiFailedEvent(planId, operation, e))
    // Continue with other scenarios
}
```

### Error Scenarios

| Scenario | Handling |
|----------|----------|
| AI generation fails | Log error, publish AI_FAILED, continue with others |
| HTTP execution fails | Record failure in result, continue with others |
| All AI calls fail | Mark run as FAILED after attempts exhausted |
| Timeout | Cancel operation, record timeout result |

## Monitoring

Key metrics to track:
- `qa_package_run_duration_seconds` - Total run time
- `ai_generation_duration_seconds` - Per-scenario AI time
- `http_execution_duration_seconds` - Per-step HTTP time
- `ai_semaphore_queue_size` - AI backpressure indicator
- `exec_semaphore_queue_size` - Execution backpressure indicator

## References

- [Kotlin Flow Documentation](https://kotlinlang.org/docs/flow.html)
- [ADR-001: Spring WebFlux with Kotlin Coroutines](ADR-001-spring-webflux-kotlin-coroutines.md)
- RFC-002: QA Package Persistence & Replay (in BUSINESS_REQUIREMENTS.md)
